# -*- coding: utf-8 -*-
"""Spam_or_harm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18X30N6645RyoZcjK9YcQx8muEOcBnq9-
"""

# program to detect the email is spam or not

import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
import string
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split


# load data
# from google.colab import files
# uploaded = files.upload()

# Read the csv file
df = pd.read_csv("emails.csv")

# To print the first five raws of data
df.head(5)

# Get the number of raws and columns
df.shape

# Get the column names
df.columns

# Check for duplicates and remove
df.drop_duplicates(inplace=True)

# show new shape
df.shape

# show the numbe of missing data for each column
df.isnull().sum()

# Download stop word packages
nltk.download('stopwords')

# Cleaning the data
# 1 removing puncations
# 2 removing stopwords words that are not need for natural language processing


def process_text(text):
    non_punc = [char for char in text if char not in string.punctuation]
    non_punc = ''.join(non_punc)

    clean_words = [word for word in non_punc.split(
    ) if word.lower() not in stopwords.words('english')]

    return clean_words

# Show tokens
df['text'].head().apply(process_text)

# Convert the collection of text to Matrix of tokens
message_bow = CountVectorizer(analyzer=process_text).fit_transform(df['text'])

# Dividing data as test set and train set
X_train, X_test, y_train, y_test = train_test_split(
    message_bow, df['spam'], test_size=0.2, random_state=0)

# get the dimension of message_bow
message_bow.shape

# Create and train our classifier using naive base classifier
classifier = MultinomialNB().fit(X_train, y_train)

# Print the prediction
print(classifier.predict(X_train))

# Print the target value
print(y_train.values)

# Its time to evaluate the prediction
pred = classifier.predict(X_train)
print(classification_report(y_train, pred))
print()

print(confusion_matrix(y_train, pred))
print()

print("Accuracy : ", accuracy_score(y_train, pred))
